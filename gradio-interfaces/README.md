# üñ•Ô∏è Creaci√≥n de Interfaces con Gradio

## üìã Descripci√≥n
Este proyecto demuestra la creaci√≥n de interfaces de usuario interactivas utilizando Gradio, un framework sencillo pero potente para Python. El trabajo muestra una progresi√≥n desde conceptos b√°sicos hasta implementaciones avanzadas que integran modelos de IA como GPT y Claude.

## üîë Tecnolog√≠as utilizadas
- **Gradio**: Framework para crear interfaces de usuario
- **OpenAI API**: Para interactuar con modelos GPT
- **Anthropic API**: Para interactuar con modelos Claude
- **BeautifulSoup**: Para extracci√≥n de datos web
- **OpenRouter**: Para gestionar diferentes modelos de IA con una √∫nica API

## üéØ Objetivos
- Aprender a crear interfaces de usuario interactivas con Gradio
- Integrar modelos de lenguaje grandes (LLMs) en aplicaciones web
- Demostrar casos de uso pr√°cticos combinando web scraping y generaci√≥n de texto por IA

## üíª Componentes principales

### 1. Configuraci√≥n del entorno
```python
import os
import requests
from bs4 import BeautifulSoup
from typing import List
from dotenv import load_dotenv
from openai import OpenAI
import gradio as gr

load_dotenv()
api_key = os.getenv('OPENAI_API_KEY')  # OpenRouter maneja todos los modelos
```

### 2. Interfaces b√°sicas
La primera interfaz muestra c√≥mo conectar una funci√≥n simple con una entrada y salida de texto:

```python
def shout(text):
    return text.upper()

gr.Interface(fn=shout, inputs="textbox", outputs="textbox").launch()
```

### 3. Integraci√≥n con modelos de IA
Implementaci√≥n de funciones para comunicarse con modelos de lenguaje:

```python
def message_gpt(prompt):
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": prompt}
    ]
    completion = openai.chat.completions.create(
        model="openai/gpt-4o-mini",
        messages=messages,
    )
    return completion.choices[0].message.content
```

### 4. Streaming de respuestas
Mejora de la experiencia de usuario mediante streaming de respuestas:

```python
def stream_gpt(prompt):
    # Configuraci√≥n de la llamada a la API
    stream = openai.chat.completions.create(
        model='gpt-4o-mini',
        messages=[
            {"role": "system", "content": system_message},
            {"role": "user", "content": prompt}
        ],
        stream=True
    )
    result = ""
    for chunk in stream:
        result += chunk.choices[0].delta.content or ""
        yield result
```

### 5. Selector de modelos
Interfaz con selector para elegir entre diferentes modelos de IA:

```python
def stream_model(prompt, model):
    if model=="GPT":
        result = stream_gpt(prompt)
    elif model=="Claude":
        result = stream_claude(prompt)
    else:
        raise ValueError("Modelo Desconocido")
    yield from result

view = gr.Interface(
    fn=stream_model,
    inputs=[
        gr.Textbox(label="Tu mensaje:"), 
        gr.Dropdown(["GPT", "Claude"], label="Selecciona un modelo:", value="GPT")
    ],
    outputs=[gr.Markdown(label="Respuesta:")],
    flagging_mode="never"
)
```

## üöÄ Aplicaci√≥n pr√°ctica: Generador de folletos empresariales

La aplicaci√≥n final combina web scraping con generaci√≥n de texto por IA para crear folletos empresariales a partir del contenido de un sitio web:

```python
class Website:
    def __init__(self, url):
        self.url = url
        response = requests.get(url)
        self.body = response.content
        soup = BeautifulSoup(self.body, 'html.parser')
        self.title = soup.title.string if soup.title else "No se ha encontrado t√≠tulo de la p√°gina"
        for irrelevant in soup.body(["script", "style", "img", "input"]):
            irrelevant.decompose()
        self.text = soup.body.get_text(separator="\n", strip=True)

    def get_contents(self):
        return f"T√≠tulo de la Web:\n{self.title}\nContenido de la Web:\n{self.text}\n\n"

def stream_brochure(company_name, url, model):
    prompt = f"Genera un folleto de la empresa {company_name}. Esta es su p√°gina de destino:\n"    
    prompt += Website(url).get_contents()
    if model=="GPT":
        result = stream_gpt(prompt)
    elif model=="Claude":
        result = stream_claude(prompt)
    else:
        raise ValueError("Modelo Desconocido")
    yield from result
```

## üìà Conclusiones

Este proyecto demuestra c√≥mo Gradio facilita la creaci√≥n de interfaces de usuario para aplicaciones de IA, permitiendo:

- R√°pido prototipado de aplicaciones web con m√≠nimo c√≥digo
- F√°cil integraci√≥n con modelos de lenguaje grandes
- Creaci√≥n de aplicaciones pr√°cticas que combinan diferentes tecnolog√≠as
- Exposici√≥n p√∫blica de interfaces para demostraci√≥n o uso compartido

Esta implementaci√≥n sirve como base para la creaci√≥n de aplicaciones m√°s complejas que requieran interacci√≥n con modelos de IA a trav√©s de interfaces amigables.